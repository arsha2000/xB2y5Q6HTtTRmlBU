{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "First, I'm going to analyze the dataset to see if there are any missing data, and whether we need to scale the features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df.isnull().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fortunately, there aren't any missing values in our dataset, but if there were, we could've either dropped the rows with missing values, or impute them. Having features that aren't on the same scale will cause problem in our model, so we need to check for that."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.describe(include='all')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems our features are all on the same scale (1-5), so we don't need to standardize them. Multicollinearity is another issue that we need to look out for. We can observe the correlation among our features with a heat plot."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# let's separate the features and the response\n",
    "df_x = df.loc[:, df.columns != 'Y']\n",
    "df_y = df['Y']\n",
    "\n",
    "df_x.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(pd.concat([df_x, df_y], axis=1).corr(), annot=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that there's a relatively high correlation between X1 and X5, and also X1 and X6. I won't remove the any of the features, but will keep this in mind. We can also do a VIF test."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "vif_dataframe = pd.DataFrame()\n",
    "vif_dataframe['feature'] = df_x.columns\n",
    "\n",
    "vif_dataframe['VIF'] = [variance_inflation_factor(df_x.values, i) for i in range(len(df_x.columns))]\n",
    "vif_dataframe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, we see there's a relatively high degree of multicollinearity among the features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_x.hist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that features X1 and X6 have relatively lower variance and are skewed. We need to consider this when performing feature selection."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.countplot(df_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The responses are balances, so we don't need to worry about it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_x.to_numpy()\n",
    "y = df_y.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f\"Train Set Count: {len(X_train)}\\nTest Set Count {len(X_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model_tree = RandomForestClassifier(random_state=123, n_estimators=50)\n",
    "model_tree.fit(X_train, y_train)\n",
    "print(model_tree.feature_importances_)\n",
    "\n",
    "sel_model = SelectFromModel(estimator=model_tree, prefit=True, threshold='mean')\n",
    "X_train_transformed = sel_model.transform(X_train)\n",
    "X_test_transformed = sel_model.transform(X_test)\n",
    "print(X_train_transformed.shape)\n",
    "print(sel_model.get_support())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We could see that the model has chosen X1, X2, X3, X5."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training\n",
    "Since the data seems to be correlated, I'm going to perform PCA to solve the multicollinearity issue."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train_transformed)\n",
    "\n",
    "pca_train = pca.transform(X_train_transformed)\n",
    "pca_test = pca.transform(X_test_transformed)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(pca_train, y_train)\n",
    "model.score(pca_test, y_test)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, model.predict(pca_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because of the nature of Principal Component Analysis, it's not easy to tell which features is more important in determining the response."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model doesn't acheive the determined 73% accuracy; however, achieving a high accuracy when we have small dataset (126 data points) could be an indication of overfitting. I think an accuracy of 61% is adequate for a model with trained on this dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d3bd7aec9d3aefc30e9f64b0bf8a3a4ade45bdcb761a3780476c4d6e5d5460fd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}